---
layout  : wiki
title   : 
summary : 
date    : 2020-05-18 12:25:23 +0900
updated : 2020-06-01 18:55:50 +0900
tags    : 
toc     : true
public  : true
parent  : 
latex   : false
---
* TOC
{:toc}


## S3(Simple Storage System)

- ETL(Extaract, Transform, Load) -> ELT(Extract, Load, Transform)
- AWS Glue
    - 다양한 데이터 스토어 간 간단한 이동, 데이터 추출 변환 로드 
    - 크롤러 -> 테이블 변형 자동 감지


### 코드

- 필기한 참조용도
- `vim ~/.aws/config`에서 region설정을 `ap-northeast-2`가 아니라 `us-east-1`로 바꿔야 작동

```python
import pandas

def main():
    ...
    cursor.execute("SELECT id FROM artists")
    
    dt = datetime.utcnow().strftime("%Y-%m-%d")
    
    # with open('top_tracks.json', 'w') as f:
    #     for i in top_tracks:
    #         json.dump(i, f)
    #         f.write(os.linesep) # 라인별 저장
    
    top_track_keys = {
        "id": "id",
        "name": "name",
        "popularity": "popularity",
        "external_url": "external_urls.spotify"
    }
    
    top_tracks = []
    for (id, ) in cursor.fetchall():
        URL = "https://api.spotify.com/v1/artists/{}/top-tracks".format(id)
        params = {
            'country': 'US'
        }
        r = requests.get(URL, params=params, headers=headers)
        raw = json.loads(r.text)
        # top_tracks.extend(raw['tracks']) 
        
        for i in raw['tracks']:
            top_track = {}
            for k, v in top_track_keys.items():
                top_track.update({k: jsonpath.jsonpath(i, v)}) # i는 딕셔너리?, jsonpath - 깔끔하게 정렬하는 방법?
                top_track.update({'artist_id': id})
                top_tracks.append(top_track)    
    
    track_ids = [i['id'][0] for i in top_tracks]
    
    top_tracks = pd.DataFrame(raw)
    top_tracks.to_parquet('top-tracks.parquet', engine='pyarrow', compressions='snappy') # 스파크에 쓸 데이터형식 - parquet을 판다스 통해 만든다, compressions -> 압축 형식
    
    s3 = boto3.resource('s3')
    object = s3.Object('spo-artists', 'dt={}/top-tracks.parquet'.format(dt)) # 첫번째 인자 - s3 버킷 이름, 두번째 인자 - 파티션으로 쓰일 키?, dt -> datetime
    data = open('top-tracks.parquet', 'rb')
    object.put(Body=data)
    
    # audio-features -> api 문서 several로 옵션 -> batch 가능
    track_batch = [track_id[i: i+100] for i in range(0, len(track_ids), 100)]
    
    audio_features = [] # audio-features는 nested 데이터가 아니므로
    for i in tracks_batch:
        ids = ','.join(i)
        URL = 'https://api.spotify.com/v1/audio-features/?ids={}'.format(ids)
        
        r = requests.get(URL, headers=headers)
        raw = json.loads(r.text)
        
        audio.features.extend(raw['audio_features'])
    
    audio_features = pd.DataFarme(audio_features)
    audio_features.to_parquet('audio-features.parquet', engine='pyarrow', compresssion='snappy')
    
    s3 = boto3.resource('s3')
    object = s3.Object('spo-artists', 'audio-features/dt={}/audio-features.parquet'.format(dt))
    data = open('audio-features.parquet', 'rb')
    object.put(Body=data)  
    
```

- 실행용도

```python
import sys
import os
import logging
import boto3
import requests
import base64
import json
import pymysql
from datetime import datetime
import pandas as pd
import jsonpath  # pip3 install jsonpath --user

client_id = "74cbd487458843f1ad3f5fa1e914c02f"
client_secret = "752e4ed11062473f9da9076c4499d51b"

host = "fastcampus.cxxbo4jh5ykm.ap-northeast-2.rds.amazonaws.com"
port = 3306
username = "sean"
database = "production"
password = "fastcampus"


def main():

    try:
        conn = pymysql.connect(host, user=username, passwd=password, db=database, port=port, use_unicode=True, charset='utf8')
        cursor = conn.cursor()
    except:
        logging.error("could not connect to rds")
        sys.exit(1)

    headers = get_headers(client_id, client_secret)

    # RDS - 아티스트 ID를 가져오고
    cursor.execute("SELECT id FROM artists LIMIT 10")

    top_track_keys = {
        "id": "id",
        "name": "name",
        "popularity": "popularity",
        "external_url": "external_urls.spotify"
    }
    # Top Tracks Spotify 가져오고
    top_tracks = []
    for (id, ) in cursor.fetchall():

        URL = "https://api.spotify.com/v1/artists/{}/top-tracks".format(id)
        params = {
            'country': 'US'
        }
        r = requests.get(URL, params=params, headers=headers)
        raw = json.loads(r.text)

        for i in raw['tracks']:
            top_track = {}
            for k, v in top_track_keys.items():
                top_track.update({k: jsonpath.jsonpath(i, v)})
                top_track.update({'artist_id': id})
                top_tracks.append(top_track)

    # track_ids
    track_ids = [i['id'][0] for i in top_tracks]

    top_tracks = pd.DataFrame(top_tracks)
    top_tracks.to_parquet('top-tracks.parquet', engine='pyarrow', compression='snappy')

    dt = datetime.utcnow().strftime("%Y-%m-%d") # utc -> unix time

    s3 = boto3.resource('s3')
    object = s3.Object('spotify-artists', 'top-tracks/dt={}/top-tracks.parquet'.format(dt))
    data = open('top-tracks.parquet', 'rb')
    object.put(Body=data)
    # S3 import

    tracks_batch = [track_ids[i: i+100] for i in range(0, len(track_ids), 100)]

    audio_features = []
    for i in tracks_batch:

        ids = ','.join(i)
        URL = "https://api.spotify.com/v1/audio-features/?ids={}".format(ids)

        r = requests.get(URL, headers=headers)
        raw = json.loads(r.text)

        audio_features.extend(raw['audio_features'])

    audio_features = pd.DataFrame(audio_features)
    audio_features.to_parquet('audio-features.parquet', engine='pyarrow', compression='snappy')

    s3 = boto3.resource('s3')
    object = s3.Object('spotify-artists', 'audio-features/dt={}/top-tracks.parquet'.format(dt))
    data = open('audio-features.parquet', 'rb')
    object.put(Body=data)



def get_headers(client_id, client_secret):

    endpoint = "https://accounts.spotify.com/api/token"
    encoded = base64.b64encode("{}:{}".format(client_id, client_secret).encode('utf-8')).decode('ascii')

    headers = {
        "Authorization": "Basic {}".format(encoded)
    }

    payload = {
        "grant_type": "client_credentials"
    }

    r = requests.post(endpoint, data=payload, headers=headers)

    access_token = json.loads(r.text)['access_token']

    headers = {
        "Authorization": "Bearer {}".format(access_token)
    }

    return headers


if __name__=='__main__':
    main()
```

## Athena 

### query

- S3에 넣은 데이터를 Athena에서 쿼리
- 쿼리를 쓴 만큼 비용 청구
    - 파티셔닝을 해야 비용 절감
    - 예) 날짜 기준으로 파티셔닝
- presto functions (검색) 사용 가능

```python
CREATE EXTERNAL TABLE IF NOT EXISTS top_tracks(
    id string,
    artist_id string,
    name string,
    popularity int,
    external_url string  # 키값을 넣은 데이터만 가져오고 안 넣을 수도 있다
) PARTITIONED BY (dt string)
STORED AS PARQUET LOCATION 's3://spotify-artists/top-tracks/' tblproperties('parquet.compress'='SNAPPY')  # tbl -> table

MSCK REPAIR TABLE top_tracks # partitions
WHERE CAST(dt AS date) = CURRENT_DATE # dt가 스트링이라 CAST
# WHERE CAST(dt AS date) >= CURRENT_DATE - INTERVAL '7' DAY # 최근 7일간
LIMIT 10
```

```python
CREATE EXTERNAL TABLE IF NOT EXISTS audio_features(
    id string,
    danceability DOUBLE,
    energy DOUBLE,
    key int,
    loudness DOUBLE,
    mode int,
    speechiness DOUBLE,
    acousticness DOUBLE,
    instrumentalness DOUBLE
) PARTITIONED BY (dt string)
STORED AS PARQUET LOCATION 's3://spotify-artists/audio-features/' tblproperties('parquet.compress'='SNAPPY')  

MSCK REPAIR TABLE audio_features 
```

## Link

- [올인원 데이터엔지니어링](https://www.fastcampus.co.kr/data_online_engineering)
